{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/watchstep/Algorithm-Python/blob/main/exllamav2_beir_rerank.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dUr9EnAUlPTO"
      },
      "source": [
        "- [Promptagator: Few-shot Dense Retrieval From 8 Examples](https://arxiv.org/abs/2209.11755)\n",
        "- [InPars: Data Augmentation for Information Retrieval using Large Language Models.](https://arxiv.org/abs/2202.05144)\n",
        "\n",
        "- https://blog.vespa.ai/improving-zero-shot-ranking-with-vespa-part-two/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hv1mAPE7i0hq",
        "outputId": "777f86f8-6ce8-4681-fc19-b65f48d15b59"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "p6wptmWpi2PR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "12e83ed9-b837-4784-fff0-d12d534f9294"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting exllamav2\n",
            "  Downloading exllamav2-0.0.9-py3-none-any.whl (91 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m91.4/91.4 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting beir\n",
            "  Downloading beir-2.0.0.tar.gz (53 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.6/53.6 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from exllamav2) (1.5.3)\n",
            "Collecting ninja (from exllamav2)\n",
            "  Downloading ninja-1.11.1.1-py2.py3-none-manylinux1_x86_64.manylinux_2_5_x86_64.whl (307 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m307.2/307.2 kB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting fastparquet (from exllamav2)\n",
            "  Downloading fastparquet-2023.10.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m48.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torch>=2.0.1 in /usr/local/lib/python3.10/dist-packages (from exllamav2) (2.1.0+cu118)\n",
            "Requirement already satisfied: safetensors>=0.3.2 in /usr/local/lib/python3.10/dist-packages (from exllamav2) (0.4.0)\n",
            "Collecting sentencepiece>=0.1.97 (from exllamav2)\n",
            "  Downloading sentencepiece-0.1.99-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m82.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pygments in /usr/local/lib/python3.10/dist-packages (from exllamav2) (2.16.1)\n",
            "Collecting websockets (from exllamav2)\n",
            "  Downloading websockets-12.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (130 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.2/130.2 kB\u001b[0m \u001b[31m16.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from exllamav2) (2023.6.3)\n",
            "Collecting sentence-transformers (from beir)\n",
            "  Downloading sentence-transformers-2.2.2.tar.gz (85 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.0/86.0 kB\u001b[0m \u001b[31m14.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting pytrec_eval (from beir)\n",
            "  Downloading pytrec_eval-0.5.tar.gz (15 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting faiss_cpu (from beir)\n",
            "  Downloading faiss_cpu-1.7.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.6/17.6 MB\u001b[0m \u001b[31m81.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting elasticsearch==7.9.1 (from beir)\n",
            "  Downloading elasticsearch-7.9.1-py2.py3-none-any.whl (219 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m219.2/219.2 kB\u001b[0m \u001b[31m21.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting datasets (from beir)\n",
            "  Downloading datasets-2.15.0-py3-none-any.whl (521 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m521.2/521.2 kB\u001b[0m \u001b[31m39.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: urllib3>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from elasticsearch==7.9.1->beir) (2.0.7)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from elasticsearch==7.9.1->beir) (2023.7.22)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.1->exllamav2) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.1->exllamav2) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.1->exllamav2) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.1->exllamav2) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.1->exllamav2) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.1->exllamav2) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.1->exllamav2) (2.1.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets->beir) (1.23.5)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets->beir) (9.0.0)\n",
            "Collecting pyarrow-hotfix (from datasets->beir)\n",
            "  Downloading pyarrow_hotfix-0.6-py3-none-any.whl (7.9 kB)\n",
            "Collecting dill<0.3.8,>=0.3.0 (from datasets->beir)\n",
            "  Downloading dill-0.3.7-py3-none-any.whl (115 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.3/115.3 kB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets->beir) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets->beir) (4.66.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets->beir) (3.4.1)\n",
            "Collecting multiprocess (from datasets->beir)\n",
            "  Downloading multiprocess-0.70.15-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m14.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets->beir) (3.8.6)\n",
            "Requirement already satisfied: huggingface-hub>=0.18.0 in /usr/local/lib/python3.10/dist-packages (from datasets->beir) (0.19.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets->beir) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets->beir) (6.0.1)\n",
            "Collecting cramjam>=2.3 (from fastparquet->exllamav2)\n",
            "  Downloading cramjam-2.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m92.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->exllamav2) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->exllamav2) (2023.3.post1)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers->beir) (4.35.2)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from sentence-transformers->beir) (0.16.0+cu118)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence-transformers->beir) (1.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence-transformers->beir) (1.11.3)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from sentence-transformers->beir) (3.8.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->beir) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->beir) (3.3.2)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->beir) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->beir) (4.0.3)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->beir) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->beir) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->beir) (1.3.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->exllamav2) (1.16.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets->beir) (3.4)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers->beir) (0.15.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=2.0.1->exllamav2) (2.1.3)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk->sentence-transformers->beir) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->sentence-transformers->beir) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers->beir) (3.2.0)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=2.0.1->exllamav2) (1.3.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision->sentence-transformers->beir) (9.4.0)\n",
            "Building wheels for collected packages: beir, pytrec_eval, sentence-transformers\n",
            "  Building wheel for beir (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for beir: filename=beir-2.0.0-py3-none-any.whl size=63550 sha256=56252273463e57bf3adc2a58a1fdd080b18df593da4c2757c045f7daeacc0b6d\n",
            "  Stored in directory: /root/.cache/pip/wheels/1c/14/96/c606ede3c10e9300ef771a6183af09d389459195ff5f854862\n",
            "  Building wheel for pytrec_eval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pytrec_eval: filename=pytrec_eval-0.5-cp310-cp310-linux_x86_64.whl size=308202 sha256=630cbd9baa14076933b2f41fa08050f7fd207760deae26cd4f66f2fb437a7bae\n",
            "  Stored in directory: /root/.cache/pip/wheels/51/3a/cd/dcc1ddfc763987d5cb237165d8ac249aa98a23ab90f67317a8\n",
            "  Building wheel for sentence-transformers (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sentence-transformers: filename=sentence_transformers-2.2.2-py3-none-any.whl size=125923 sha256=521e5cbefab91d49a2aa5ee39a6876f9d2eab6b4bb15acdf7df67d154e9b8fb4\n",
            "  Stored in directory: /root/.cache/pip/wheels/62/f2/10/1e606fd5f02395388f74e7462910fe851042f97238cbbd902f\n",
            "Successfully built beir pytrec_eval sentence-transformers\n",
            "Installing collected packages: sentencepiece, ninja, faiss_cpu, websockets, pytrec_eval, pyarrow-hotfix, elasticsearch, dill, cramjam, multiprocess, fastparquet, exllamav2, datasets, sentence-transformers, beir\n",
            "Successfully installed beir-2.0.0 cramjam-2.7.0 datasets-2.15.0 dill-0.3.7 elasticsearch-7.9.1 exllamav2-0.0.9 faiss_cpu-1.7.4 fastparquet-2023.10.1 multiprocess-0.70.15 ninja-1.11.1.1 pyarrow-hotfix-0.6 pytrec_eval-0.5 sentence-transformers-2.2.2 sentencepiece-0.1.99 websockets-12.0\n"
          ]
        }
      ],
      "source": [
        "!pip install exllamav2  beir"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "x7SKofSti2al",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6e22d892-7b50-44e8-c86f-46c1f7665dd3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Git LFS initialized.\n"
          ]
        }
      ],
      "source": [
        "!git lfs install"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "krBb0PZRi6Ri",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8b4db9f4-fb03-44be-c1d8-8fb9175e3f30"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Mistral-7B-instruct-exl2'...\n",
            "remote: Enumerating objects: 52, done.\u001b[K\n",
            "remote: Counting objects: 100% (49/49), done.\u001b[K\n",
            "remote: Compressing objects: 100% (49/49), done.\u001b[K\n",
            "remote: Total 52 (delta 16), reused 0 (delta 0), pack-reused 3\u001b[K\n",
            "Unpacking objects: 100% (52/52), 623.04 KiB | 3.15 MiB/s, done.\n"
          ]
        }
      ],
      "source": [
        "!git clone -b 4.0bpw https://huggingface.co/turboderp/Mistral-7B-instruct-exl2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "p5wXIsU0nlWL"
      },
      "outputs": [],
      "source": [
        "import os, sys, argparse\n",
        "\n",
        "p_prompt = f\"\"\"\n",
        "Passage: <P> Given the provided passage, generate 3 similar passages on related topic: <T>\n",
        "\"\"\"\n",
        "\n",
        "q_prompt = \"\"\"\n",
        "<P> Review the given passages and answer a specific and detailed query. {'Query: Your query here.'}”\n",
        "\"\"\"\n",
        "\n",
        "parser = argparse.ArgumentParser(description = \"Prompting with ExLlamaV2\")\n",
        "parser.add_argument(\"--dataset\", type = str, default ='nq')\n",
        "parser.add_argument(\"--seed\", type = int, default = 2023)\n",
        "parser.add_argument(\"--topk\", type=int, default=10)\n",
        "parser.add_argument(\"--model_dir\", type=str, default=\"/content/Mistral-7B-instruct-exl2\")\n",
        "parser.add_argument(\"--p_prompt\", type=str, default=p_prompt)\n",
        "parser.add_argument(\"--q_prompt\", type=str, default=q_prompt)\n",
        "\n",
        "args = parser.parse_args([])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 137,
          "referenced_widgets": [
            "89fa4fbf9b7d4c9d943203f2e87c28e9",
            "8b8d301867e44c08accf257164528809",
            "91c58f8de88a4a788cc2603f65edaca6",
            "9faedaebd2214c8d9f4e441d2ca5e211",
            "6e46e330dba64178903edba535fe95f7",
            "4b41df690d894a549bcec345d1f52da7",
            "9054eb9f071a475ebf56aa11b81ac3b5",
            "48d2f577357848af813be24bc33bf08d",
            "a89d2af1bbe64e2d821c4e14cb65f0b9",
            "4dbcec2a3df442d2866f53ea56a86215",
            "e647090b0f734335ae81f0f8a66af349",
            "501e3862cf814e1b8c5c403a87cd7be9",
            "2e55452213a54aed9d99e4f83c082eba",
            "9eb81f9b7c8e428296817cf2342bc33c",
            "8a01e251ea0d40b1852fe62f14f9ca39",
            "efac791dc5a44c878078143979100cd0",
            "49e104183b83487d86c7319eeba18bc1",
            "dfeb56560be443a1ba5a643fd7893fae",
            "cd6590099c4040509e945aa05cb1386e",
            "1a9840bdc70e4a93a07f6c680913b338",
            "da6097f8d3614727ab3eff9cc3f775d0",
            "9a524016d5d84ecc8136cbea8db9e50d"
          ]
        },
        "id": "SDUNVYV_jL5M",
        "outputId": "753fe8d2-8e34-4914-cea4-7d3ff00b29f7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/beir/util.py:2: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
            "  from tqdm.autonotebook import tqdm\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "/content/nq.zip:   0%|          | 0.00/475M [00:00<?, ?iB/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "89fa4fbf9b7d4c9d943203f2e87c28e9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/2681468 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "501e3862cf814e1b8c5c403a87cd7be9"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "from beir import util\n",
        "from beir.datasets.data_loader import GenericDataLoader\n",
        "\n",
        "url = f\"https://public.ukp.informatik.tu-darmstadt.de/thakur/BEIR/datasets/{args.dataset}.zip\"\n",
        "data_path = util.download_and_unzip(url, '/content')\n",
        "\n",
        "corpus, queries, qrels = GenericDataLoader(data_folder=data_path).load(split=\"test\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Atc4Z4GcCbFO",
        "outputId": "17b2aefc-761b-4887-ee98-cfc3f20e2e36"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "elasticsearch-oss-7.9.2-linux-x86_64.tar.gz: OK\n"
          ]
        }
      ],
      "source": [
        "# download & setup Elasticsearch\n",
        "%%bash\n",
        "\n",
        "wget -q https://artifacts.elastic.co/downloads/elasticsearch/elasticsearch-oss-7.9.2-linux-x86_64.tar.gz\n",
        "wget -q https://artifacts.elastic.co/downloads/elasticsearch/elasticsearch-oss-7.9.2-linux-x86_64.tar.gz.sha512\n",
        "tar -xzf elasticsearch-oss-7.9.2-linux-x86_64.tar.gz\n",
        "sudo chown -R daemon:daemon elasticsearch-7.9.2/\n",
        "shasum -a 512 -c elasticsearch-oss-7.9.2-linux-x86_64.tar.gz.sha512"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "8eFMGMogCfVi"
      },
      "outputs": [],
      "source": [
        "%%bash --bg\n",
        "\n",
        "sudo -H -u daemon elasticsearch-7.9.2/bin/elasticsearch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H5NuFZh8Ch1Q",
        "outputId": "d0fa0577-ce49-4147-cb56-050b624baf13"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root        2906    2901  0 06:31 ?        00:00:00 sudo -H -u daemon elasticsearch-7.9.2/bin/elasti\n",
            "daemon      2907    2906 39 06:31 ?        00:00:17 /content/elasticsearch-7.9.2/jdk/bin/java -Xshar\n",
            "root        3322    3320  0 06:32 ?        00:00:00 grep elasticsearch\n"
          ]
        }
      ],
      "source": [
        "%%bash\n",
        "\n",
        "ps -ef | grep elasticsearch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pekqc5FVCmCv",
        "outputId": "a027c072-585b-4e84-c382-0d71f57bb5a1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "  \"name\" : \"dfdcb6919169\",\n",
            "  \"cluster_name\" : \"elasticsearch\",\n",
            "  \"cluster_uuid\" : \"9fLaMVCpR9q87we_5jb0Zw\",\n",
            "  \"version\" : {\n",
            "    \"number\" : \"7.9.2\",\n",
            "    \"build_flavor\" : \"oss\",\n",
            "    \"build_type\" : \"tar\",\n",
            "    \"build_hash\" : \"d34da0ea4a966c4e49417f2da2f244e3e97b4e6e\",\n",
            "    \"build_date\" : \"2020-09-23T00:45:33.626720Z\",\n",
            "    \"build_snapshot\" : false,\n",
            "    \"lucene_version\" : \"8.6.2\",\n",
            "    \"minimum_wire_compatibility_version\" : \"6.8.0\",\n",
            "    \"minimum_index_compatibility_version\" : \"6.0.0-beta1\"\n",
            "  },\n",
            "  \"tagline\" : \"You Know, for Search\"\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "%%bash\n",
        "\n",
        "curl -sX GET \"localhost:9200/\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2QvoBGp7BsIQ",
        "outputId": "c7f75222-3ae7-457f-f1eb-fda0294e2f68"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 47%|████▋     | 1265501/2681468 [03:50<04:12, 5596.95docs/s]"
          ]
        }
      ],
      "source": [
        "from beir.retrieval.search.lexical import BM25Search as BM25\n",
        "from beir.retrieval.evaluation import EvaluateRetrieval\n",
        "\n",
        "hostname = \"localhost\"\n",
        "index_name = \"nq\"\n",
        "initialize = True\n",
        "\n",
        "model = BM25(index_name=index_name, hostname=hostname, initialize=initialize)\n",
        "retriever = EvaluateRetrieval(model)\n",
        "\n",
        "results = retriever.retrieve(corpus, queries)\n",
        "# ndcg, _map, recall, precision = retriever.evaluate(qrels, results, retriever.k_values)\n",
        "output = {'retrieval': EvaluateRetrieval.evaluate(qrels, results, retriever.k_values)}"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from exllamav2 import(\n",
        "    ExLlamaV2,\n",
        "    ExLlamaV2Config,\n",
        "    ExLlamaV2Cache,\n",
        "    ExLlamaV2Tokenizer,\n",
        ")\n",
        "\n",
        "from exllamav2.generator import (\n",
        "    ExLlamaV2BaseGenerator,\n",
        "    ExLlamaV2Sampler\n",
        ")\n",
        "\n",
        "from beir.reranking import Rerank\n",
        "from typing import List, Tuple\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# https://github.com/beir-cellar/beir/wiki/Evaluate-your-custom-model\n",
        "# https://github.com/Muennighoff/sgpt/blob/main/crossencoder/beir/sgptce.py\n",
        "# https://github.com/beir-cellar/beir/blob/main/examples/retrieval/evaluation/reranking/evaluate_bm25_ce_reranking.py\n",
        "# https://github.com/beir-cellar/beir/blob/main/beir/reranking/models/mono_t5.py\n",
        "\n",
        "class ExLlamaV2Reranker:\n",
        "  def __init__(self, p_prompt=args.p_prompt, q_prompt=args.q_prompt, model_dir=args.model_dir, seed=args.seed **kwargs):\n",
        "    self.p_prompt = p_prompt\n",
        "    self.q_prompt = q_prompt\n",
        "    self.seed = seed\n",
        "\n",
        "    config = ExLlamaV2Config()\n",
        "    config.model_dir = model_dir\n",
        "    config.prepare()\n",
        "\n",
        "    self.model = ExLlamaV2(config)\n",
        "    if not model.loaded:\n",
        "      self.cache = ExLlamaV2Cache(model, lazy = True)\n",
        "      model.load_autosplit(self.cache)\n",
        "      self.cache = None\n",
        "\n",
        "    self.tokenizer = ExLlamaV2Tokenizer(config)\n",
        "    self.generator = ExLlamaV2BaseGenerator(model, cache, self.tokenizer)\n",
        "    self.generator.warmup()\n",
        "\n",
        "    self.settings = ExLlamaV2Sampler.Settings()\n",
        "    self.settings.temperature = 0.6\n",
        "    self.settings.top_k = 50\n",
        "    self.settings.top_p = 0.9\n",
        "    self.settings.token_repetition_penalty = 1.15\n",
        "    self.settings.disallow_tokens(self.tokenizer, [self.tokenizer.eos_token_id])\n",
        "\n",
        "\n",
        "    def predict(self, sentences: List[Tuple[str,str]], batch_size: int, **kwags) -> List[float]:\n",
        "      scores = []\n",
        "      for query, psg in sentences:\n",
        "        self.p_prompt = self.p_prompt.replace('<P>', psg['text']).replace('<T>', psg['title']).strip()\n",
        "        generated = self.generator.generate_simple(self.p_prompt, self.settings, seed=args.seed)\n",
        "        self.q_prompt = self.q_prompt.replace('<P>', generated).strip()\n",
        "        input_ids = self.tokenizer.encode(self.q_prompt)\n",
        "        logits = self.model.forward(input_ids, self.cache)\n",
        "        logits = logits[:, :-1, :]\n",
        "        logits = logits.float() + 1e-10\n",
        "        log_probs = F.log_softmax(logits, dim=-1)\n",
        "        scores.append(log_probs)\n",
        "\n",
        "      assert len(scores) == len(sentences)\n",
        "      return scores\n"
      ],
      "metadata": {
        "id": "QNgyL8V0Ylj9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DhA2240iDDCZ"
      },
      "outputs": [],
      "source": [
        "reranker = Rerank(ExLlamaV2Reranker(), batch_size=128)\n",
        "rerank_results = reranker.rerank(corpus, queries, results, top_k=10)\n",
        "\n",
        "output['reranking'] = EvaluateRetrieval.evaluate(qrels, rerank_results, retriever.k_values)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# save output\n",
        "import json\n",
        "\n",
        "with open(f'/content/{args.dataset}_eval_ouput.json', 'w') as f:\n",
        "  json.dump(output, f, indent=4)"
      ],
      "metadata": {
        "id": "9TzvjK2jyJi4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F4PoQhNJjOfL"
      },
      "outputs": [],
      "source": [
        "te_text = corpus['doc787']['text']\n",
        "te_title = corpus['doc787']['title']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l9y_cfvmjQiY"
      },
      "outputs": [],
      "source": [
        "prompt = f\"\"\"\n",
        "Passage: {te_text} Please generate 3 passages akin to the given passages, focusing on {te_title}\n",
        "\"\"\"\n",
        "\n",
        "# max_new_tokens = 400\n",
        "\n",
        "output = generator.generate_simple(prompt, settings, seed = 2023)\n",
        "print(output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SCKq-CDQjSGf"
      },
      "outputs": [],
      "source": [
        "prompt = f\"\"\"\n",
        "Passage: {te_text} Given the provided passage, generate 3 similar passages on related title {te_title}\n",
        "\"\"\"\n",
        "\n",
        "max_new_tokens = 400\n",
        "\n",
        "output = generator.generate_simple(prompt, settings, max_new_tokens, seed = 2023)\n",
        "print(output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PmA30M7RjUvx"
      },
      "outputs": [],
      "source": [
        "prompt2 = f\"{output} Review the given passages and answer a specific and detailed query. {'Query: Your query here.'}\"\n",
        "max_new_tokens = 30\n",
        "\n",
        "output2 = generator.generate_simple(prompt2, settings, max_new_tokens, seed = 2023)\n",
        "print(output2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KIO9sD2GjWYM"
      },
      "outputs": [],
      "source": [
        "class NQDataset:\n",
        "  def __init__(self, corpus, queries):\n",
        "    self.corpus = corpus\n",
        "    self.queries = queries\n",
        "    self.qids = list(queries.keys())\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.qids)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    query = self.queries[self.qids[idx]]\n",
        "    return query"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oUkhO-Hoo6Af"
      },
      "outputs": [],
      "source": [
        "with torch.inference_mode():\n",
        "  cache = ExLlamaV2Cache(model)\n",
        "\n",
        "  input_ids1 = tokenizer.encode(prompt1)\n",
        "  logits = model.forward(input_ids, cache)\n",
        "\n",
        "\n",
        "  output1 = generator.generate()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n12YSeNjjXoI"
      },
      "outputs": [],
      "source": [
        "input_ids = tokenizer.encode(prompt1)\n",
        "prompt_tokens = input_ids.shape[-1]\n",
        "\n",
        "output = generator.generate(batch[\"input_ids\"].cuda(), settings, seed=2023)\n",
        "\n",
        "decode"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOtRGHZZzl/ISq59nOUBtA2",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "89fa4fbf9b7d4c9d943203f2e87c28e9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8b8d301867e44c08accf257164528809",
              "IPY_MODEL_91c58f8de88a4a788cc2603f65edaca6",
              "IPY_MODEL_9faedaebd2214c8d9f4e441d2ca5e211"
            ],
            "layout": "IPY_MODEL_6e46e330dba64178903edba535fe95f7"
          }
        },
        "8b8d301867e44c08accf257164528809": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4b41df690d894a549bcec345d1f52da7",
            "placeholder": "​",
            "style": "IPY_MODEL_9054eb9f071a475ebf56aa11b81ac3b5",
            "value": "/content/nq.zip: 100%"
          }
        },
        "91c58f8de88a4a788cc2603f65edaca6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_48d2f577357848af813be24bc33bf08d",
            "max": 498307926,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a89d2af1bbe64e2d821c4e14cb65f0b9",
            "value": 498307926
          }
        },
        "9faedaebd2214c8d9f4e441d2ca5e211": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4dbcec2a3df442d2866f53ea56a86215",
            "placeholder": "​",
            "style": "IPY_MODEL_e647090b0f734335ae81f0f8a66af349",
            "value": " 475M/475M [00:26&lt;00:00, 13.6MiB/s]"
          }
        },
        "6e46e330dba64178903edba535fe95f7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4b41df690d894a549bcec345d1f52da7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9054eb9f071a475ebf56aa11b81ac3b5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "48d2f577357848af813be24bc33bf08d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a89d2af1bbe64e2d821c4e14cb65f0b9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4dbcec2a3df442d2866f53ea56a86215": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e647090b0f734335ae81f0f8a66af349": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "501e3862cf814e1b8c5c403a87cd7be9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2e55452213a54aed9d99e4f83c082eba",
              "IPY_MODEL_9eb81f9b7c8e428296817cf2342bc33c",
              "IPY_MODEL_8a01e251ea0d40b1852fe62f14f9ca39"
            ],
            "layout": "IPY_MODEL_efac791dc5a44c878078143979100cd0"
          }
        },
        "2e55452213a54aed9d99e4f83c082eba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_49e104183b83487d86c7319eeba18bc1",
            "placeholder": "​",
            "style": "IPY_MODEL_dfeb56560be443a1ba5a643fd7893fae",
            "value": "100%"
          }
        },
        "9eb81f9b7c8e428296817cf2342bc33c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cd6590099c4040509e945aa05cb1386e",
            "max": 2681468,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1a9840bdc70e4a93a07f6c680913b338",
            "value": 2681468
          }
        },
        "8a01e251ea0d40b1852fe62f14f9ca39": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_da6097f8d3614727ab3eff9cc3f775d0",
            "placeholder": "​",
            "style": "IPY_MODEL_9a524016d5d84ecc8136cbea8db9e50d",
            "value": " 2681468/2681468 [00:27&lt;00:00, 133035.88it/s]"
          }
        },
        "efac791dc5a44c878078143979100cd0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "49e104183b83487d86c7319eeba18bc1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dfeb56560be443a1ba5a643fd7893fae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cd6590099c4040509e945aa05cb1386e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1a9840bdc70e4a93a07f6c680913b338": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "da6097f8d3614727ab3eff9cc3f775d0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9a524016d5d84ecc8136cbea8db9e50d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}